{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self,step_cost) :\n",
    "        self.row = 5\n",
    "        self.column = 5\n",
    "        self.i = 4\n",
    "        self.j = 0\n",
    "        self.config(step_cost)\n",
    "\n",
    "    def config(self,step_cost):\n",
    "        reward = {}\n",
    "\n",
    "        for p in range(self.row):\n",
    "            for q in range(self.column):\n",
    "                if p==0 and q==4:\n",
    "                    reward[(p,q)] = 1\n",
    "                elif p==1 and q==4:\n",
    "                    reward[(p,q)] = -1\n",
    "                elif p==2 and q==1:\n",
    "                    reward[(p,q)] = 0\n",
    "                elif p==3 and q==3:\n",
    "                    reward[(p,q)] = 0\n",
    "                else :\n",
    "                    reward[(p,q)] = step_cost\n",
    "\n",
    "        action = {(0, 0): {'D','R'},\n",
    "        (0, 1):{'L','D','R'},\n",
    "        (0, 2): {'L','D','R'},\n",
    "        (0, 3): {'L','D','R'},\n",
    "        (1, 0): {'U','R','D'},\n",
    "        (1, 1): {'U','D','R','L'},\n",
    "        (1, 2): {'U','D','R','L'},\n",
    "        (1, 3): {'U','D','R','L'},\n",
    "        (2, 0): {'U','R','D'},\n",
    "        (2, 1): {'U','D','R','L'},\n",
    "        (2, 2): {'U','D','R','L'},\n",
    "        (2, 3): {'U','D','R','L'},\n",
    "        (2, 4): {'D','U','L'},\n",
    "        (3, 0): {'U','R','D'},\n",
    "        (3, 1): {'U','D','R','L'},\n",
    "        (3, 2): {'U','D','R','L'},\n",
    "        (3, 3): {'U','D','R','L'},\n",
    "        (3, 4): {'D','L','U'},\n",
    "        (4, 0): {'U','R'},\n",
    "        (4, 1): {'U','R','L'},\n",
    "        (4, 2): {'U','R','L'},\n",
    "        (4, 3): {'U','R','L'},\n",
    "        (4, 4): {'U','L'},}\n",
    "\n",
    "        prob = {(0, 0): {'D','R'},\n",
    "        (0, 1):{'L','D','R'},\n",
    "        (0, 2): {'L','D','R'},\n",
    "        (0, 3): {'L','D','R'},\n",
    "        (1, 0): {'U','R','D'},\n",
    "        (1, 1): {'U','D','R','L'},\n",
    "        (1, 2): {'U','D','R','L'},\n",
    "        (1, 3): {'U','D','R','L'},\n",
    "        (2, 0): {'U','R','D'},\n",
    "        (2, 1): {'U','D','R','L'},\n",
    "        (2, 2): {'U','D','R','L'},\n",
    "        (2, 3): {'U','D','R','L'},\n",
    "        (2, 4): {'D','U','L'},\n",
    "        (3, 0): {'U','R','D'},\n",
    "        (3, 1): {'U','D','R','L'},\n",
    "        (3, 2): {'U','D','R','L'},\n",
    "        (3, 3): {'U','D','R','L'},\n",
    "        (3, 4): {'D','L','U'},\n",
    "        (4, 0): {'U','R'},\n",
    "        (4, 1): {'U','R','L'},\n",
    "        (4, 2): {'U','R','L'},\n",
    "        (4, 3): {'U','R','L'},\n",
    "        (4, 4): {'U','L'},}\n",
    "\n",
    "        prob = {}\n",
    "        for i in action:\n",
    "            for j in action[i]:\n",
    "                d = np.random.randint(5)/10\n",
    "                for k in action[i]:\n",
    "                    if(j==k):\n",
    "                        p = 1 - d\n",
    "                    else:\n",
    "                        p = d / (len(action[i])-1)\n",
    "                    if (i[0],i[1],j) in prob :\n",
    "                        prob[i[0],i[1],j][self.get_nextState(i[0],i[1],k)] = p\n",
    "                    else:\n",
    "                        prob[i[0],i[1],j] = {self.get_nextState(i[0],i[1],k):p}\n",
    "\n",
    "        self.set(reward,action,prob)\n",
    "\n",
    "    def set(self,reward, action, prob):\n",
    "        self.reward = reward\n",
    "        self.action = action\n",
    "        self.prob = prob\n",
    "\n",
    "    def get_nextState(self,si,sj,action):\n",
    "        if action == \"U\":\n",
    "            si -= 1\n",
    "        elif action == \"D\":\n",
    "            si += 1\n",
    "        elif action == \"R\":\n",
    "            sj += 1\n",
    "        elif action == \"D\":\n",
    "            sj -= 1\n",
    "        return si,sj\n",
    "\n",
    "    def get_reward(self,si,sj):\n",
    "        return self.reward[(si,sj)]\n",
    "\n",
    "    def move(self,action):\n",
    "        self.i,self.j = self.get_nextState(self.i,self.j,action)\n",
    "        return self.get_reward(self.i,self.j)\n",
    "    \n",
    "    def terminate(self):\n",
    "        if (self.i,self.j) in self.action:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def current_state(self):\n",
    "        return self.i,self.j\n",
    "    \n",
    "    def is_terminal(self,i,j):\n",
    "        if (i,j) in self.action:\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GridWorld(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transition and reward function of S' / s2\n",
    "transition = {}\n",
    "reward_s2 = {}\n",
    "\n",
    "for i in range(g.row):\n",
    "    for j in range(g.column):\n",
    "        if(i,j) in g.action:\n",
    "            for action in g.action[(i,j)]:\n",
    "                for k in g.prob[i,j,action]:\n",
    "                    transition[(i,j,action,k[0],k[1])]=g.prob[i,j,action][k]\n",
    "                    reward_s2[(i,j,action,k[0],k[1])] = g.get_reward(k[0],k[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_policy():\n",
    "        policy = {\n",
    "        (0, 0): {'R':1},\n",
    "        (0, 1):{'R':1},\n",
    "        (0, 2): {'R':1},\n",
    "        (0, 3): {'R':1},\n",
    "        (1, 0): {'U':1},\n",
    "        (1, 1): {'U':1},\n",
    "        (1, 2): {'U':1},\n",
    "        (1, 3): {'U':1},\n",
    "        (2, 0): {'U':1},\n",
    "        (2, 2): {'U':1},\n",
    "        (2, 3): {'U':1},\n",
    "        (2, 4): {'L':1},\n",
    "        (3, 0): {'U':1},\n",
    "        (3, 1): {'R':1},\n",
    "        (3, 2): {'U':1},\n",
    "        (3, 4): {'U':1},\n",
    "        (4, 0): {'U':.5,'R':.5},\n",
    "        (4, 1): {'U':1},\n",
    "        (4, 2): {'U':1},\n",
    "        (4, 3): {'L':1},\n",
    "        (4, 4): {'L':1},\n",
    "        (0, 4): {'D':1},\n",
    "        (1,4) : {'U':1}}\n",
    "\n",
    "        return policy\n",
    "\n",
    "policy = set_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate Value\n",
    "V = {}\n",
    "\n",
    "for p in range(g.row):\n",
    "    for q in range(g.column):\n",
    "            V[(p,q)] = 0\n",
    "\n",
    "delta = 0.00001\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print value\n",
    "def plot_value(V):\n",
    "    print(\"Value\")\n",
    "    for i in range(g.row):\n",
    "        print (\"---\"*7)\n",
    "        print(\"|\",end=\" \")\n",
    "        for j in range(g.column):\n",
    "            print(\"%.2f|\" %V[(i,j)],end=\" \")\n",
    "        print(\"\")\n",
    "    print (\"---\"*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLICY\n",
      "---------------------\n",
      "| {'R': 1} | {'R': 1} | {'R': 1} | {'R': 1} | {'D': 1} | \n",
      "---------------------\n",
      "| {'U': 1} | {'U': 1} | {'U': 1} | {'U': 1} | {'U': 1} | \n",
      "---------------------\n",
      "| {'U': 1} |   | {'U': 1} | {'U': 1} | {'L': 1} | \n",
      "---------------------\n",
      "| {'U': 1} | {'R': 1} | {'U': 1} |   | {'U': 1} | \n",
      "---------------------\n",
      "| {'U': 0.5, 'R': 0.5} | {'U': 1} | {'U': 1} | {'L': 1} | {'L': 1} | \n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "#print policy\n",
    "\n",
    "def print_policy(policy):\n",
    "    print(\"POLICY\")\n",
    "    for i in range(g.row):\n",
    "        print (\"---\"*7)\n",
    "        print(\"|\",end=\" \")\n",
    "        for j in range(g.column):\n",
    "            if (i,j) in policy:\n",
    "                print(policy[(i,j)],\"|\",end=\" \")\n",
    "            else:\n",
    "                print(\" \",\"|\",end=\" \")\n",
    "        print(\"\")\n",
    "    print (\"---\"*7)\n",
    "\n",
    "print_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "\n",
    "def policy_evaluation(policy,V):\n",
    "    iter = 0\n",
    "    while True:\n",
    "        diff = 0\n",
    "        for si in range(g.row):\n",
    "            for sj in range(g.column):\n",
    "                if not g.is_terminal(si,sj):\n",
    "                    temp = {}\n",
    "                    new_v = float('-inf')\n",
    "                    for action in g.action[(si,sj)]:\n",
    "                        temp_v = 0\n",
    "                        for s2i in range(g.row):\n",
    "                            for s2j in range(g.column):\n",
    "                                trs = transition[(si,sj,action,s2i,s2j)] if (si,sj,action,s2i,s2j) in transition else 0\n",
    "                                rew = reward_s2[(si,sj,action,s2i,s2j)] if (si,sj,action,s2i,s2j) in reward_s2 else 0\n",
    "                                temp_v += trs *(rew+ gamma * V[(s2i,s2j)])\n",
    "                        if temp_v>new_v:\n",
    "                            new_v = temp_v\n",
    "                    \n",
    "                    diff = max(diff,np.abs(V[(si,sj)]-temp_v))\n",
    "                    V[(si,sj)]=temp_v\n",
    "        iter = iter+1\n",
    "        # print(\"Itereation :\", iter, \"      Diff :\",diff)\n",
    "        # plot_value(V)\n",
    "        if diff < delta:\n",
    "            break\n",
    "\n",
    "    return V\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "\n",
    "def policy_improvement(policy,V):\n",
    "    temp_policy = {}\n",
    "    for si in range(g.row):\n",
    "        for sj in range(g.column):\n",
    "            if not g.is_terminal(si,sj):\n",
    "                temp = {}\n",
    "                for action in g.action[(si,sj)]:\n",
    "                    temp_v = 0\n",
    "                    for s2i in range(g.row):\n",
    "                        for s2j in range(g.column):\n",
    "                            trs = transition[(si,sj,action,s2i,s2j)] if (si,sj,action,s2i,s2j) in transition else 0\n",
    "                            rew = reward_s2[(si,sj,action,s2i,s2j)] if (si,sj,action,s2i,s2j) in reward_s2 else 0\n",
    "                            temp_v += trs *(rew+ gamma * V[(s2i,s2j)])\n",
    "                    temp[action] = temp_v\n",
    "            val = max(temp.values())\n",
    "            res = [key for key in temp if temp[key] == val] \n",
    "            temp_policy[(si,sj)] = {res[0]:1}\n",
    "    policy = temp_policy\n",
    "        \n",
    "\n",
    "    return policy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value\n",
      "---------------------\n",
      "| -0.00| -0.00| -0.03| -0.10| 0.00| \n",
      "---------------------\n",
      "| -0.00| -0.00| -0.02| -0.11| 0.00| \n",
      "---------------------\n",
      "| -0.00| -0.00| -0.01| -0.04| -0.49| \n",
      "---------------------\n",
      "| -0.00| -0.00| -0.01| -0.02| -0.14| \n",
      "---------------------\n",
      "| -0.00| -0.00| -0.00| 0.00| -0.10| \n",
      "---------------------\n",
      "POLICY\n",
      "---------------------\n",
      "| {'D': 1} | {'D': 1} | {'L': 1} | {'R': 1} | {'R': 1} | \n",
      "---------------------\n",
      "| {'D': 1} | {'L': 1} | {'L': 1} | {'D': 1} | {'D': 1} | \n",
      "---------------------\n",
      "| {'D': 1} | {'D': 1} | {'D': 1} | {'D': 1} | {'D': 1} | \n",
      "---------------------\n",
      "| {'U': 1} | {'U': 1} | {'D': 1} | {'D': 1} | {'D': 1} | \n",
      "---------------------\n",
      "| {'U': 1} | {'L': 1} | {'R': 1} | {'L': 1} | {'L': 1} | \n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "policy= set_policy()\n",
    "\n",
    "V = policy_evaluation(policy,V)\n",
    "plot_value(V)\n",
    "policy = policy_improvement(policy,V)\n",
    "\n",
    "\n",
    "\n",
    "print_policy(policy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
